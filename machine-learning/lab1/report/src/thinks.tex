\section{Выводы}
В ходе выполнения лабораторной работы я познакомился с линейными моделями классического машинного обучения: логистической регрессией, методом опорных векторов, наивным байесовским классификатором и методом k-ближайших соседей. Больше всего заинтересовал алгоритм k-ближайших соседей для классификации, так как он кажется интуитивно наиболее хорошим. Однако его недостаток в большой вычислительной сложности.

Основная сложность в работе --- реализация каждого метода вручную, пришлось искать очень много методов из библиотек numpy и scikit-learn, чтобы легко работать с данными. Пожалуй, это заняло большую часть времени.

В результате набор данных Smoker Condition получилось разделить линейными моделями с поразительной точностью 99\%. Точность такая высокая, потому что перед обучением я удалил около двух десятков выбросов и неполных данных.

Особенно хочется отметить, что такой точности получается добиться далеко не всегда, потому что реальный мир сложнее, чем линейная модель. При поиске подходящего набора данных я находил такие, где точки классов перемешанны самым разнообразным образом. Летом хочу из интереса попробовать применить алгоритмы классического машинного обучения на этих наборах.
\pagebreak
